name: Process $dataset_id
on:
  workflow_dispatch:
    inputs:
      endpoint:
        description: 'Upload to SPARQL endpoint'
        required: true
        default: 'https://graphdb.dumontierlab.com/repositories/test/statements'
      graph:
        description: 'In the Graph'
        required: true
        default: 'https://w3id.org/d2s/graph/$dataset_id'

jobs:

  generate-rdf:
    runs-on: ubuntu-latest
    outputs:
      rdf-output: ${{ steps.stepupload.outputs.rdf_output }}

    steps:
    - uses: actions/checkout@v2

    - name: Download data
      run: datasets/$dataset_id/scripts/download.sh

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.7

    - name: Install Python dependencies
      run: |
        python -m pip install -r requirements.txt

    - name: Run preprocessing Python script
      run: python datasets/$dataset_id/scripts/preprocessing.py

    - name: Run RML mapper to generate RDF
      uses: vemonet/rmlmapper-java@v4.9.0
      with:
        mapping: datasets/$dataset_id/mapping/mappings.rml.ttl
        output: rdf-output.nt
        
    - name: Upload RDF output artifact to GitHub
      id: stepupload
      uses: actions/upload-artifact@v1
      with:
        name: rdf-output
        path: rdf-output.nt

  upload-rdf:
    runs-on: ubuntu-latest
    needs: generate-rdf
    
    steps:
    - uses: actions/checkout@v2

    - name: Get RDF output artifact from previous job
      uses: actions/download-artifact@v1
      with:
        name: rdf-output

    - name: Generate HDT compressed file from RDF output
      uses: vemonet/rdfhdt-action@master
      with:
        input: rdf-output/rdf-geonames.nt
        output: hdt-geonames.hdt

    - name: Upload HDT output artifact to GitHub
      uses: actions/upload-artifact@v1
      with:
        name: hdt-output
        path: hdt-geonames.hdt

    - name: Upload RDF to the defined SPARQL endpoint
      uses: MaastrichtU-IDS/RdfUpload@master
      with:
        file: rdf-output/*.nt
        endpoint: ${{ github.event.inputs.endpoint }}
        user: ${{ secrets.GRAPHDB_USER }}
        password: ${{ secrets.GRAPHDB_PASSWORD }}
        graph: ${{ github.event.inputs.graph }}

    - name: Compute and insert HCLS descriptive metadata
      uses: vemonet/sparql-operations-action@v1
      with:
        file: https://github.com/MaastrichtU-IDS/d2s-scripts-repository/tree/master/sparql/compute-hcls-stats
        endpoint: ${{ github.event.inputs.endpoint }}
        user: ${{ secrets.GRAPHDB_USER }}
        password: ${{ secrets.GRAPHDB_PASSWORD }}
        inputvar: ${{ github.event.inputs.graph }}
        outputvar: https://w3id.org/d2s/metadata
        servicevar: ${{ github.event.inputs.endpoint }}
